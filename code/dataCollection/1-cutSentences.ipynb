{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from random import sample\n",
    "from patterns import word_patterns,sent_patterns,count_sentence_grammar_level_new_word,count_sentence_grammar_level_new_sent\n",
    "\n",
    "\n",
    "standard = pd.read_excel('standard.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "针对词级别的分句\n",
    "'''\n",
    "\n",
    "# 细节上调整句子格式，以。结尾\n",
    "def sentFormat(sentence):\n",
    "    if (sentence[-1:]=='，'):\n",
    "        return sentence[:-1]+'。'\n",
    "    return sentence\n",
    "\n",
    "\n",
    "#将长句按逗号分段，便于词级语法匹配更精准\n",
    "def short_cut(sentence):\n",
    "    sentence = sentence.replace('\\n','').replace(' ','')\n",
    "    \n",
    "    flagchs = ['，','！','？','；','。']\n",
    "    ret_sents = []\n",
    "    \n",
    "    start = 0\n",
    "    add_flag = 0  # 0:单独成句 1:长度过短 2:《》分隔 3:（） 分隔 4:‘或“分隔\n",
    "    i = 0\n",
    "    while (i<len(sentence)):             \n",
    "        # 去掉对话形式\n",
    "        if (sentence[i]=='：' and (sentence[i-1]=='A' or sentence[i-1]=='B')): \n",
    "            start = i+1\n",
    "            \n",
    "        if (sentence[i] in flagchs):     \n",
    "            if (add_flag==0):\n",
    "                if (i-start<8):\n",
    "                    add_flag = 1  \n",
    "                elif ('《' in sentence[start:i] and '》' not in sentence[start:i]):\n",
    "                    add_flag = 2\n",
    "                elif ('（' in sentence[start:i] and '）' not in sentence[start:i]):\n",
    "                    add_flag = 3\n",
    "                elif ('“' in sentence[start:i] and (i+1<len(sentence)) and sentence[i+1]=='”'):\n",
    "                    ret_sents.append(sentence[start:i+2])\n",
    "                    start = i+2\n",
    "                    addI_flag = 1\n",
    "                    i += 1                    \n",
    "                elif (('“' in sentence[start:i] and '”' not in sentence[start:i]) or ('‘' in sentence[start:i] and '’' not in sentence[start:i])):\n",
    "                    add_flag = 4           \n",
    "                else:\n",
    "                    ret_sents.append(sentFormat(sentence[start:i+1]))\n",
    "                    start = i+1\n",
    "            elif (add_flag==1):\n",
    "                if (i-start>=8):\n",
    "                    add_flag = 0\n",
    "                    i -= 1\n",
    "            elif (add_flag==2):\n",
    "                if ('》' in sentence[start:i]):\n",
    "                    ret_sents.append(sentFormat(sentence[start:i+1]))\n",
    "                    add_flag = 0\n",
    "                    start = i+1\n",
    "            elif (add_flag==3):\n",
    "                if ('）' in sentence[start:i]):\n",
    "                    ret_sents.append(sentFormat(sentence[start:i+1]))\n",
    "                    add_flag = 0\n",
    "                    start = i+1\n",
    "            elif (add_flag==4):\n",
    "                if ('’' in sentence[start:i] or '”' in sentence[start:i]):\n",
    "                    ret_sents.append(sentFormat(sentence[start:i+1]))\n",
    "                    add_flag = 0\n",
    "                    start = i+1\n",
    "                elif (i+1<len(sentence) and sentence[i+1]=='”'):\n",
    "                    ret_sents.append(sentFormat(sentence[start:i+2]))\n",
    "                    add_flag = 0\n",
    "                    start = i+2\n",
    "        i += 1\n",
    "    return ret_sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“什么是真正的朋友？”', '有些人觉得就是能和自己一起快乐的人，其实朋友应该像镜子，能帮你看清自己的缺点；', '无论你成功或者失败，永远都支持你。']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "针对句级别的分句\n",
    "'''\n",
    "def sent_cut(sentence):\n",
    "    sentence = sentence.replace('\\n','').replace(' ','')\n",
    "    \n",
    "    flagchs = ['！','？','；','。']\n",
    "    ret_sents = []\n",
    "    \n",
    "    start = 0\n",
    "    add_flag = 0  # 0:单独成句 1:长度过短 2:《》分隔 3:（） 分隔 4:‘或“分隔\n",
    "    i = 0\n",
    "    while (i<len(sentence)):            \n",
    "        if (sentence[i]=='：'):\n",
    "            if (sentence[i-1]=='A' or sentence[i-1]=='B'):  # 去掉对话形式\n",
    "                start = i+1\n",
    "                \n",
    "        if (sentence[i] in  flagchs):\n",
    "            if (add_flag==0):\n",
    "                if (i-start<8):\n",
    "                    add_flag = 1  \n",
    "                elif ('《' in sentence[start:i] and '》' not in sentence[start:i]):\n",
    "                    add_flag = 2\n",
    "                elif ('（' in sentence[start:i] and '）' not in sentence[start:i]):\n",
    "                    add_flag = 3\n",
    "                elif ('“' in sentence[start:i] and (i+1<len(sentence)) and sentence[i+1]=='”'):\n",
    "                    ret_sents.append(sentence[start:i+2])\n",
    "                    start = i+2\n",
    "                    addI_flag = 1\n",
    "                elif (('“' in sentence[start:i] and '”' not in sentence[start:i]) or ('‘' in sentence[start:i] and '’' not in sentence[start:i])):\n",
    "                    add_flag = 4\n",
    "                else:\n",
    "                    ret_sents.append(sentence[start:i+1])\n",
    "                    start = i+1\n",
    "            elif (add_flag==1):\n",
    "                if (i-start>=8):\n",
    "                    add_flag = 0\n",
    "                    i -= 1\n",
    "            elif (add_flag==2):\n",
    "                if ('》' in sentence[start:i]):\n",
    "                    ret_sents.append(sentence[start:i+1])\n",
    "                    add_flag = 0\n",
    "                    start = i+1\n",
    "            elif (add_flag==3):\n",
    "                if ('）' in sentence[start:i]):\n",
    "                    ret_sents.append(sentence[start:i+1])\n",
    "                    add_flag = 0\n",
    "                    start = i+1\n",
    "            elif (add_flag==4):\n",
    "                if ('’' in sentence[start:i] or '”' in sentence[start:i]):\n",
    "                    ret_sents.append(sentence[start:i+1])\n",
    "                    add_flag = 0\n",
    "                    start = i+1\n",
    "                elif (i+1<len(sentence) and sentence[i+1]=='”'):\n",
    "                    ret_sents.append(sentence[start:i+2])\n",
    "                    add_flag = 0\n",
    "                    start = i+2\n",
    "        i += 1\n",
    "    return ret_sents\n",
    "\n",
    "sent_cut('“什么是真正的朋友？”有些人觉得就是能和自己一起快乐的人，其实朋友应该像镜子，能帮你看清自己的缺点；无论你成功或者失败，永远都支持你。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对词级和句级分开提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def buildDataset_char(data, save_path):\n",
    "#     sentences = []\n",
    "#     labels = []\n",
    "#     matches = []\n",
    "#     labelids = []\n",
    "#     for t_ in data['text']:\n",
    "#         # 匹配词级语法点\n",
    "#         shorterwords = short_cut(t_)\n",
    "#         for shorterword in shorterwords:\n",
    "#             label, match = count_sentence_grammar_level_new_word(shorterword)\n",
    "#             i = 0\n",
    "#             for labelid in label:\n",
    "#                 labelname = standard.loc[labelid-1,'grammar']\n",
    "#                 sentences.append(shorterword)\n",
    "#                 labels.append(labelname)\n",
    "#                 matches.append(match[i])\n",
    "#                 labelids.append(labelid)\n",
    "#                 i+=1\n",
    "\n",
    "#     df = pd.DataFrame({'text':sentences, 'label':labels, 'match':matches, 'label_id':labelids})\n",
    "#     df.to_csv(save_path,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def buildDataset_sent(data, save_path):\n",
    "#     sentences = []\n",
    "#     labels = []\n",
    "#     matches = []\n",
    "#     labelids = []\n",
    "#     for t_ in data['text']:\n",
    "#         # 匹配句级语法点  \n",
    "#         sents = sent_cut(t_)\n",
    "#         for sent in sents:\n",
    "#             label, match = count_sentence_grammar_level_new_sent(sent,standard)\n",
    "#             i = 0\n",
    "#             for labelid in label:\n",
    "#                 labelname = standard.loc[labelid-1,'grammar']\n",
    "#                 labelcontent = standard.loc[labelid-1,'content']\n",
    "#                 sentences.append(sent)\n",
    "#                 labels.append(labelname)\n",
    "#                 matches.append(labelcontent)\n",
    "#                 labelids.append(labelid)\n",
    "#                 i+=1\n",
    "        \n",
    "#     df = pd.DataFrame({'text':sentences, 'label':labels, 'match':matches, 'label_id':labelids})\n",
    "#     df.to_csv(save_path,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2010 = pd.read_excel('../textExtract/data/2010.xlsx')\n",
    "# data2012 = pd.read_excel('../textExtract/data/2012.xlsx')\n",
    "# data2014 = pd.read_excel('../textExtract/data/2014.xlsx')\n",
    "# data2018 = pd.read_excel('../textExtract/data/2018.xlsx')\n",
    "\n",
    "# path2010_char = 'data/2010_aug_char.csv'\n",
    "# path2012_char = 'data/2012_aug_char.csv'\n",
    "# path2014_char = 'data/2014_aug_char.csv'\n",
    "# path2018_char = 'data/2018_aug_char.csv'\n",
    "\n",
    "# path2010_sent = 'data/2010_aug_sent.csv'\n",
    "# path2012_sent = 'data/2012_aug_sent.csv'\n",
    "# path2014_sent = 'data/2014_aug_sent.csv'\n",
    "# path2018_sent = 'data/2018_aug_sent.csv'\n",
    "\n",
    "# # buildDataset_char(data2010, path2010_char)\n",
    "# # buildDataset_char(data2012, path2012_char)\n",
    "# # buildDataset_char(data2014, path2014_char)\n",
    "# # buildDataset_char(data2018, path2018_char)\n",
    "\n",
    "# # buildDataset_sent(data2010, path2010_sent)\n",
    "# buildDataset_sent(data2012, path2012_sent)\n",
    "# # buildDataset_sent(data2014, path2014_sent)\n",
    "# # buildDataset_sent(data2018, path2018_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词级句级混合提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataset_mix(data, save_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    matches = []\n",
    "    labelids = []\n",
    "    _id=0\n",
    "    for t_ in data['text']:\n",
    "        _id+=1\n",
    "        # 匹配句级语法点  \n",
    "        sents = sent_cut(t_)\n",
    "        for sent in sents:\n",
    "            label_sent, match_sent = count_sentence_grammar_level_new_sent(sent,standard)  # 匹配句级语法点\n",
    "            label_char, match_char = count_sentence_grammar_level_new_word(sent)  # 匹配词级语法点\n",
    "        \n",
    "            sent_matches, char_matches = [], []\n",
    "            # 句级\n",
    "            for labelid in label_sent:\n",
    "                labelname = standard.loc[labelid-1,'grammar']\n",
    "                labelcontent = standard.loc[labelid-1,'content']\n",
    "                sentences.append(sent)\n",
    "                labels.append(labelname)\n",
    "                matches.append(labelcontent)\n",
    "                sent_matches.append(labelcontent)\n",
    "                labelids.append(labelid)\n",
    "                \n",
    "            # 词级\n",
    "            i = 0\n",
    "            for labelid in label_char:\n",
    "                flag = 0  # 记录词级语法点是否有重复\n",
    "                for sent_match in sent_matches:\n",
    "                    if (match_char[i] in sent_match):\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if match_char[i] in char_matches:\n",
    "                    flag = 1\n",
    "                    \n",
    "                if (flag==0):\n",
    "                    labelname = standard.loc[labelid-1,'grammar']\n",
    "                    sentences.append(sent)\n",
    "                    labels.append(labelname)\n",
    "                    matches.append(match_char[i])\n",
    "                    char_matches.append(match_char[i])\n",
    "                    labelids.append(labelid)\n",
    "                i+=1\n",
    "                    \n",
    "        \n",
    "    df = pd.DataFrame({'text':sentences, 'label':labels, 'match':matches, 'label_id':labelids})\n",
    "    df.to_csv(save_path,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2010 = pd.read_excel('../textExtract/data/2010.xlsx')\n",
    "data2012 = pd.read_excel('../textExtract/data/2012.xlsx')\n",
    "data2014 = pd.read_excel('../textExtract/data/2014.xlsx')\n",
    "data2018 = pd.read_excel('../textExtract/data/2018.xlsx')\n",
    "\n",
    "path2010_mix = 'data/2010_aug_mix.csv'\n",
    "path2012_mix = 'data/2012_aug_mix.csv'\n",
    "path2014_mix = 'data/2014_aug_mix.csv'\n",
    "path2018_mix = 'data/2018_aug_mix.csv'\n",
    "\n",
    "# buildDataset_mix(data2010, path2010_mix)\n",
    "# buildDataset_mix(data2012, path2012_mix)\n",
    "# buildDataset_mix(data2014, path2014_mix)\n",
    "buildDataset_mix(data2018, path2018_mix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
